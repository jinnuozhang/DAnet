{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac312e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import xlsxwriter\n",
    "def savexlsx(data,name):\n",
    "    workbook=xlsxwriter.Workbook('{}.xlsx'.format(name))\n",
    "    worksheet=workbook.add_worksheet()\n",
    "    hang = data.shape[0]\n",
    "    lie = data.shape[1]\n",
    "    for col in range(int(hang)):\n",
    "        for row in range(int(lie)):\n",
    "            worksheet.write(col,row,data[col,row])\n",
    "    workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Split_or_not = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b88f00",
   "metadata": {},
   "source": [
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd3f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('data.xlsx', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bacb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "orignal_data = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orignal_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = orignal_data[:,:473]\n",
    "label = orignal_data[:,473:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ec760",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Split_or_not  == True:\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, label, test_size=0.3)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.1)\n",
    "else:\n",
    "    train_x = pd.read_excel('train_x.xlsx', header=None).values\n",
    "    valid_x = pd.read_excel('valid_x.xlsx', header=None).values\n",
    "    train_y = pd.read_excel('train_y.xlsx', header=None).values\n",
    "    valid_y = pd.read_excel('valid_y.xlsx', header=None).values\n",
    "    test_x = pd.read_excel('test_x.xlsx', header=None).values\n",
    "    test_y = pd.read_excel('test_y.xlsx', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc700f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1 = train_y[:,0]\n",
    "train_y2 = keras.utils.np_utils.to_categorical(train_y[:,1])\n",
    "valid_y1 = valid_y[:,0]\n",
    "valid_y2 = keras.utils.np_utils.to_categorical(valid_y[:,1])\n",
    "test_y1 = test_y[:,0]\n",
    "test_y2 = keras.utils.to_categorical(test_y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dfe231",
   "metadata": {},
   "outputs": [],
   "source": [
    "savexlsx(train_x,'train_x-1')\n",
    "savexlsx(valid_x,'valid_x-1')\n",
    "savexlsx(test_x,'test_x-1')\n",
    "savexlsx(train_y,'train_y-1')\n",
    "savexlsx(valid_y,'valid_y-1')\n",
    "savexlsx(test_y,'test_y-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568294a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Reshape,Add,Multiply,merge,Input,Dense, Activation,Dense,Dropout,Flatten,BatchNormalization,Conv1D\n",
    "from keras.layers import MaxPooling1D,AveragePooling1D,LeakyReLU,GlobalAveragePooling1D\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam,SGD,Adamax\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import losses\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0],train_x.shape[1],1)\n",
    "valid_x = valid_x.reshape(valid_x.shape[0],valid_x.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c75e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Res_block(X,filters):\n",
    "    \n",
    "    F1,F2 = filters\n",
    " \n",
    "    X_shortcut = X\n",
    " \n",
    "    X = Conv1D(filters = F1, kernel_size = 1, strides = 1,kernel_initializer='random_uniform',bias_initializer='zeros')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv1D(filters = F2, kernel_size = 3, strides = 1, padding = 'same',kernel_initializer='random_uniform',bias_initializer='zeros')(X)\n",
    "    X_shortcut = Conv1D(F2, kernel_size = 1, strides = 1, kernel_initializer='random_uniform',bias_initializer='zeros')(X_shortcut)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    " \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet_new(input_shape = (473,), classes1 = 1, classes2 = 2):\n",
    " \n",
    "    X_input = Input(input_shape)\n",
    "    X1 = Dense(128, activation = 'relu', name = 'base_1',kernel_initializer='random_uniform',bias_initializer='zeros')(X_input)\n",
    "    X1 = Dense(473, name = 'base_2', kernel_initializer='random_uniform',bias_initializer='zeros',)(X1)\n",
    "    X = Multiply()([X1, X_input])\n",
    "\n",
    "    \n",
    "    X = Reshape((473, 1))(X)\n",
    "    X = Res_block(X,filters=[32,16])\n",
    " \n",
    "    X = AveragePooling1D(3, name = 'avg_pool')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(128, activation = 'relu',kernel_initializer='random_uniform',bias_initializer='zeros')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(64, activation = 'relu',kernel_initializer='random_uniform',bias_initializer='zeros')(X)\n",
    "    X = Dense(classes1, activation = 'sigmoid',name='x1',kernel_initializer='random_uniform',bias_initializer='zeros')(X)\n",
    "\n",
    "\n",
    "    X_c = Dense(256, activation = 'relu',name='x2_1',kernel_initializer='random_uniform',bias_initializer='zeros')(X_input)\n",
    "    X_c = Dense(128, activation = 'relu',name='x2_2',kernel_initializer='random_uniform',bias_initializer='zeros')(X_c)\n",
    "    X_c = Dense(classes2, activation = 'softmax',name='x2_3',kernel_initializer='random_uniform',bias_initializer='zeros')(X_c)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = [X,X_c] , name = 'LPNet')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in model.layers:\n",
    "    name = str(layers.name)\n",
    "    if name.startswith(\"x2\"):\n",
    "        layers.trainable=True\n",
    "    else:\n",
    "        layers.trainable=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss={'x1':'mean_squared_error','x2_3':'categorical_crossentropy'}, loss_weights={'x1':0,'x2_3':1},optimizer=Adamax(lr=0.0001), metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names1 = 'model_cls_epoch:{epoch:02d}-val_acc:{val_x2_4_acc:.4f}.hdf5'\n",
    "save_model1 = ModelCheckpoint(filepath= model_names1, monitor='val_x2_4_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c2825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "record_h=model.fit(train_x, {'x1':train_y1,'x2_4':train_y2}, epochs=6000,batch_size=16, validation_data=(valid_x, {'x1':valid_y1,'x2_4':valid_y2}),callbacks=[save_model1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a0a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_h1 = record_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(record_h1.history['loss'])\n",
    "plt.plot(record_h1.history['val_loss'])\n",
    "plt.plot(record_h1.history['x2_4_acc'])\n",
    "plt.plot(record_h1.history['val_x2_4_acc'])\n",
    "plt.title(\"cls model loss and acc\")\n",
    "plt.ylabel(\"loss and acc\") \n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train_loss\",\"test_loss\",\"train_acc\",\"test_acc\"],loc=\"upper right\")\n",
    "plt.savefig(\"cls.jpg\",dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463e054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ec8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('model_cls_epoch:xxxx-val_acc:xxxxx.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cdd03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = model1.predict(train_x)\n",
    "y2 = model1.predict(valid_x)\n",
    "y3 = model1.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed8f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y11 = np.argmax(y1[1],1).reshape(-1,1)\n",
    "y12 = np.argmax(y2[1],1).reshape(-1,1)\n",
    "y13 = np.argmax(y2[1],1).reshape(-1,1)\n",
    "y14 = y1[0].reshape(-1,1)\n",
    "y15 = y2[0].reshape(-1,1)\n",
    "y16 = y3[0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy1 = np.concatenate((y14,y11),axis=1)\n",
    "yy2 = np.concatenate((y15,y12),axis=1)\n",
    "yy3 = np.concatenate((y16,y13),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699061eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "savexlsx(yy1.reshape(-1,2),'train_cls_pre_y')\n",
    "savexlsx(yy2.reshape(-1,2),'valid_cls_pre_y')\n",
    "savexlsx(yy3.reshape(-1,2),'test_cls_pre_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb33581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in model1.layers:\n",
    "    name = str(layers.name)\n",
    "    if name.startswith(\"x2\"):\n",
    "        layers.trainable=False\n",
    "    else:\n",
    "        layers.trainable=True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6965c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names2 = 'model_pro_epoch:{epoch:02d}-val_x1_loss:{val_x1_loss:.4f}.hdf5'\n",
    "save_model = ModelCheckpoint(filepath= model_names2, monitor='val_x1_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee1261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss={'x1':'mean_squared_error','x2_4':'categorical_crossentropy'}, loss_weights={'x1':1,'x2_4':0},optimizer=Adamax(lr=0.0001), metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8f849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "record_h2=model1.fit(train_x, {'x1':train_y1,'x2_4':train_y2}, epochs=6000,batch_size=32, validation_data=(valid_x, {'x1':valid_y1,'x2_4':valid_y2}),callbacks=[save_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3258275",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(record_h2.history['x1_loss'])\n",
    "plt.plot(record_h2.history['val_x1_loss'])\n",
    "plt.title(\"reg model loss and acc\")\n",
    "plt.ylabel(\"loss and acc\") \n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train_loss\",\"test_loss\"],loc=\"upper right\")\n",
    "plt.savefig(\"reg.jpg\",dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7156f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('model_pro_epoch:xxxx-val_x1_loss:xxxx.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ef819",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = model1.predict(train_x)\n",
    "y2 = model1.predict(valid_x)\n",
    "y1 = y1[0]\n",
    "y2 = y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f514794",
   "metadata": {},
   "outputs": [],
   "source": [
    "savexlsx(y1.reshape(-1,1),'train_reg_pre_y')\n",
    "savexlsx(y2.reshape(-1,1),'test_reg_pre_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffceb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = record_h1.history['loss']\n",
    "val_loss = record_h1.history['val_loss']\n",
    "acc = record_h1.history['x2_4_acc']\n",
    "val_acc = record_h1.history['val_x2_4_acc']\n",
    "log_data = np.stack((loss, val_loss, acc,val_acc), axis=1)\n",
    "savexlsx(log_data,'log1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada851b3",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = load_model('model_epoch:487-val_loss:2.4914.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf2954",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_p.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savexlsx(y,'train_pre_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee02bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = model_p.predict(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc8e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "savexlsx(y2,'valid_pre_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd97456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = model_p.predict(test_x)\n",
    "savexlsx(y3,'test_pre_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'base_4'\n",
    "intermediate_layer_model = Model(inputs=model1.input,outputs=model1.get_layer(layer_name).output)#创建的新模型\n",
    "output1 = intermediate_layer_model.predict(valid_x)\n",
    "output2 = intermediate_layer_model.predict(train_x)\n",
    "output3 = intermediate_layer_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827391d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "savexlsx(output1,'valid_attention_value')\n",
    "savexlsx(output2,'train_attention_value')\n",
    "savexlsx(output3,'test_attention_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'multiply_2'\n",
    "intermediate_layer_model = Model(inputs=model1.input,outputs=model1.get_layer(layer_name).output)#创建的新模型\n",
    "output4 = intermediate_layer_model.predict(valid_x)\n",
    "output5 = intermediate_layer_model.predict(train_x)\n",
    "output6 = intermediate_layer_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "savexlsx(output4,'test_attention_out')\n",
    "savexlsx(output5,'train_attention_out')\n",
    "savexlsx(output6,'test_attention_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a14b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbedd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2820eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac5befc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c271770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378cd69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a51742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52070c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005a8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e6e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947bd788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb673f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3117d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a03fa57f",
   "metadata": {},
   "source": [
    "from keras.layers import Input,Conv2D, MaxPooling2D,Flatten,Dense,Embedding,Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "nb_classes = 100\n",
    "feature_size = 32\n",
    "\n",
    "input_image = Input(shape=(224,224,3))\n",
    "cnn = Conv2D(10, (2,2))(input_image)\n",
    "cnn = MaxPooling2D((2,2))(cnn)\n",
    "cnn = Flatten()(cnn)\n",
    "feature = Dense(feature_size, activation='relu')(cnn)\n",
    "predict = Dense(nb_classes, activation='softmax', name='softmax')(feature) #至此，得到一个常规的softmax分类模型\n",
    "\n",
    "input_target = Input(shape=(1,))\n",
    "centers = Embedding(nb_classes, feature_size)(input_target) #Embedding层用来存放中心\n",
    "l2_loss = Lambda(lambda x: K.sum(K.square(x[0]-x[1][:,0]), 1, keepdims=True), name='l2_loss')([feature,centers])\n",
    "\n",
    "model_train = Model(inputs=[input_image,input_target], outputs=[predict,l2_loss])\n",
    "model_train.compile(optimizer='adam', loss=['sparse_categorical_crossentropy',lambda y_true,y_pred: y_pred], loss_weights=[1.,0.2], metrics={'softmax':'accuracy'})\n",
    "\n",
    "model_predict = Model(inputs=input_image, outputs=predict)\n",
    "model_predict.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_train.fit([train_images,train_targets], [train_targets,random_y], epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea73af50cda964fd19b2fbd3d08fd0bc5f318459fd18038db32d5ad9c1ed7a99"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
